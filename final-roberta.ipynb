{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7672323,"sourceType":"datasetVersion","datasetId":4475176},{"sourceId":7690058,"sourceType":"datasetVersion","datasetId":4487720}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch torchvision torchaudio\n!pip install transformers\n!pip install scikit-learn\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oGdVTbsw9yF9","outputId":"02094401-27db-465c-b6ce-fa020e622268","execution":{"iopub.status.busy":"2024-02-24T07:33:00.131875Z","iopub.execute_input":"2024-02-24T07:33:00.132242Z","iopub.status.idle":"2024-02-24T07:33:37.410656Z","shell.execute_reply.started":"2024-02-24T07:33:00.132209Z","shell.execute_reply":"2024-02-24T07:33:37.409437Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.16.2)\nRequirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (2.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2023.12.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.24.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.31.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (9.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2023.11.17)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.37.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.24.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.1)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.12.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.24.4)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import RobertaTokenizer, RobertaModel\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport numpy as np\n\n# Define your dataset class\nclass SentimentDataset(Dataset):\n    def __init__(self, dataframe, tokenizer, max_len):\n        self.data = dataframe\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        text = str(self.data.iloc[idx]['review'])\n        label = self.data.iloc[idx]['sentiment']\n\n        # Map string labels to numerical values\n        label_map = {'positive': 1, 'negative': 0}\n        label = label_map[label]\n\n        encoding = self.tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            return_token_type_ids=False,\n            padding='max_length',\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors='pt'\n        )\n\n        return {\n            'text': text,\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'label': torch.tensor(label, dtype=torch.long)\n        }\n","metadata":{"id":"Ni3-in909141","execution":{"iopub.status.busy":"2024-02-24T07:34:48.627209Z","iopub.execute_input":"2024-02-24T07:34:48.627927Z","iopub.status.idle":"2024-02-24T07:34:55.404202Z","shell.execute_reply.started":"2024-02-24T07:34:48.627892Z","shell.execute_reply":"2024-02-24T07:34:55.403424Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Define your model\nclass SentimentClassifier(nn.Module):\n    def __init__(self, roberta_model, num_classes):\n        super(SentimentClassifier, self).__init__()\n        self.roberta = roberta_model\n        self.dropout = nn.Dropout(0.1)\n        self.fc = nn.Linear(self.roberta.config.hidden_size, num_classes)\n\n    def forward(self, input_ids, attention_mask):\n        _, pooled_output = self.roberta(input_ids=input_ids, attention_mask=attention_mask, return_dict=False)\n        output = self.dropout(pooled_output)\n        output = self.fc(output)\n        return output\n\n","metadata":{"id":"qpm0bqKE95Rr","execution":{"iopub.status.busy":"2024-02-24T07:35:00.285183Z","iopub.execute_input":"2024-02-24T07:35:00.285725Z","iopub.status.idle":"2024-02-24T07:35:00.292379Z","shell.execute_reply.started":"2024-02-24T07:35:00.285693Z","shell.execute_reply":"2024-02-24T07:35:00.291544Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n","metadata":{"id":"Um5zP_Gt-6XF","execution":{"iopub.status.busy":"2024-02-24T07:35:05.462409Z","iopub.execute_input":"2024-02-24T07:35:05.463096Z","iopub.status.idle":"2024-02-24T07:35:05.777713Z","shell.execute_reply.started":"2024-02-24T07:35:05.463062Z","shell.execute_reply":"2024-02-24T07:35:05.776751Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#loading the dataset to a pandas DataFrame\n\ndf = pd.read_csv('/kaggle/input/imdb-asg/train.csv', encoding='ISO-8859-1')\ndf2 = pd.read_csv('/kaggle/input/imdb-asg/test.csv', encoding='ISO-8859-1')","metadata":{"id":"-i7ZHyFh_Q5w","execution":{"iopub.status.busy":"2024-02-24T07:35:08.096572Z","iopub.execute_input":"2024-02-24T07:35:08.097577Z","iopub.status.idle":"2024-02-24T07:35:09.386698Z","shell.execute_reply.started":"2024-02-24T07:35:08.097540Z","shell.execute_reply":"2024-02-24T07:35:09.385785Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import time\nfrom tqdm import tqdm\n\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(df['review'], df['sentiment'], test_size=0.2, random_state=42)\n\n# Initialize RoBERTa tokenizer and model\ntokenizer = RobertaTokenizer.from_pretrained('FacebookAI/roberta-base')\nroberta_model = RobertaModel.from_pretrained('FacebookAI/roberta-base')\n\n    # Define constants\nMAX_LEN = 128\nBATCH_SIZE = 64\nNUM_CLASSES = 2  # Assuming binary classification (positive/negative)\nLEARNING_RATE = 5e-5\n\n\n# Create datasets and dataloaders\ntrain_dataset = SentimentDataset(df, tokenizer, MAX_LEN)\ntrain_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n\nval_dataset = SentimentDataset(df2, tokenizer, MAX_LEN)\nval_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n\n    # Initialize the model\nmodel = SentimentClassifier(roberta_model, NUM_CLASSES)\n\n    # Define loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n\n    # Train the model\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\n\n    # Define the number of epochs\nnum_epochs = 3  # or any other number you prefer\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":280},"id":"nT539-ol99BO","outputId":"5ff9b7d4-8160-401d-affb-84e93c7ff883","execution":{"iopub.status.busy":"2024-02-24T09:56:45.311183Z","iopub.execute_input":"2024-02-24T09:56:45.312119Z","iopub.status.idle":"2024-02-24T09:56:46.713046Z","shell.execute_reply.started":"2024-02-24T09:56:45.312082Z","shell.execute_reply":"2024-02-24T09:56:46.712198Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"import time\n\nfor epoch in range(num_epochs):\n    model.train()\n    epoch_loss = 0\n    start_time = time.time()  # Start timing\n    progress_bar = tqdm(train_dataloader, desc=f'Epoch {epoch + 1}/{num_epochs}', leave=False)\n    for batch in progress_bar:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['label'].to(device)\n\n        optimizer.zero_grad()\n        outputs = model(input_ids, attention_mask)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        epoch_loss += loss.item()\n        progress_bar.set_postfix({'training_loss': epoch_loss / len(train_dataloader)})  # Update progress bar with loss\n\n    # Calculate training time\n    train_time = time.time() - start_time\n    \n    # Validation\n    model.eval()\n    val_predictions = []\n    val_targets = []\n    start_time = time.time()  # Start timing\n    with torch.no_grad():\n        for batch in val_dataloader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].to(device)\n\n            outputs = model(input_ids, attention_mask)\n            _, preds = torch.max(outputs, dim=1)\n\n            val_predictions.extend(preds.cpu().numpy())\n            val_targets.extend(labels.cpu().numpy())\n\n    # Calculate validation time\n    val_time = time.time() - start_time\n\n    val_accuracy = accuracy_score(val_targets, val_predictions)\n    print(f\"Epoch {epoch + 1}/{num_epochs}, Validation Accuracy: {val_accuracy}, Training Time: {train_time}, Validation Time: {val_time}\")\n","metadata":{"id":"OA_9lCKG6nBf","execution":{"iopub.status.busy":"2024-02-24T09:57:12.305593Z","iopub.execute_input":"2024-02-24T09:57:12.306381Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"                                                                                  \r","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"id":"nf4hMQQkB4TA"},"execution_count":null,"outputs":[]}]}